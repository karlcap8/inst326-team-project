
# ğŸ—ï¸ Research Data Cleaning & Validation Pipeline  
## **System Architecture Document**

This Architecture document explains the inheritance hierarchy, polymorphism decisions, design patterns, and composition structures used in our **Survey Data Cleaning & Validation Pipeline**.  


---
# ğŸ§± Architecture Overview
raw CSV
   â†“
load_raw_csv()
   â†“
Pipeline
   â”œâ”€â”€ HeaderNormalizer
   â”œâ”€â”€ PIIRemover
   â””â”€â”€ TypeCaster
   â†“
cleaned DataFrame
   â†“
RulesValidator
   â†“
ValidationReport
   â†“
save_cleaned_csv() + save_validation_report()
   â†“
(optional) save_state()


The architecture cleanly separates:

Transformation logic (pure functions or small classes)

Pipeline orchestration (Pipeline)

Validation rules

I/O + persistence

Application runner

# ğŸ“ Complete System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ABSTRACT BASE LAYER                              â”‚
â”‚                       (Defines Interface Contracts)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                        Transformer (ABC)                      â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 â”‚ + name : str                                                  â”‚
 â”‚ + notes : str                                                 â”‚
 â”‚ + created_at : datetime                                       â”‚
 â”‚ + _history : list[str]                                        â”‚
 â”‚                                                               â”‚
 â”‚ @property                                                     â”‚
 â”‚ + required_columns : list[str]   (ABSTRACT)                   â”‚
 â”‚                                                               â”‚
 â”‚ @abstractmethod                                               â”‚
 â”‚ + _apply(df) â†’ DataFrame                                      â”‚
 â”‚                                                               â”‚
 â”‚ + apply(df) â†’ DataFrame  (TEMPLATE METHOD)                    â”‚
 â”‚ + _preflight(df)                                              â”‚
 â”‚ + _log(message)                                               â”‚
 â”‚ + history() â†’ list[str]                                       â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–²
                             â”‚ inherits
                             â”‚

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                 CONCRETE IMPLEMENTATION LAYER                          â”‚
â”‚                              (Inheritance & Polymorphism for Cleaning)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HeaderNormalizer     â”‚   â”‚       PIIRemover        â”‚   â”‚         TypeCaster          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + required_columns = [] â”‚   â”‚ + columns : list[str]   â”‚   â”‚ + type_map : dict           â”‚
â”‚ + _apply(df)            â”‚   â”‚ + required_columns = [] â”‚   â”‚ + required_columns = []     â”‚
â”‚   â†’ cleans headers      â”‚   â”‚ + _apply(df)            â”‚   â”‚ + _apply(df)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â†’ drops PII columns   â”‚   â”‚   â†’ converts column types   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â”‚ used by
                                      â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           COMPOSITION LAYER                               â”‚
â”‚                        (System-Level Coordination)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤


  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                             Pipeline                              â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ + steps : list[Transformer]   â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HAS-MANY steps        â”‚
  â”‚ + history : list[str]                                             â”‚
  â”‚                                                                   â”‚
  â”‚ + run(df)                                                         â”‚
  â”‚      â†’ runs each Transformer polymorphically                      â”‚
  â”‚      â†’ collects each stepâ€™s log history                           â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                             â”‚
                             â–¼

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        Validation Subsystem                       â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ RulesValidator                                                    â”‚
  â”‚   + check(df, rules) â†’ ValidationReport                           â”‚
  â”‚                                                                   â”‚
  â”‚ ValidationReport                                                  â”‚
  â”‚   + issues : list[ValidationIssue]                                â”‚
  â”‚   + is_valid : bool                                               â”‚
  â”‚   + to_markdown()                                                 â”‚
  â”‚                                                                   â”‚
  â”‚ ValidationIssue                                                   â”‚
  â”‚   + column : str                                                  â”‚
  â”‚   + message : str                                                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

# ğŸ” Key Architectural Relationships

## **1. Inheritance (is-a)**

- `HeaderNormalizer` **is a** `Transformer`
- `PIIRemover` **is a** `Transformer`
- `TypeCaster` **is a** `Transformer`

**Why this design?**

All cleaning steps:
- Follow a common interface  
- Require consistent preflight checks  
- Need shared logging and history  
- Must be swappable in any order  

Putting shared logic in the ABC enables each subclass to focus solely on specific cleaning logic.

---

## **2. Composition (has-a)**

- `Pipeline` **has many** `Transformer` objects  
- `RulesValidator` **produces** a `ValidationReport`  
- `ValidationReport` **has many** `ValidationIssue` objects  

**Why composition instead of inheritance?**

A Pipeline is not a Transformer â€” it *uses* Transformers.  
This preserves conceptual clarity and allows:

- Reordering steps  
- Adding new Transformers without modifying Pipeline  
- Clean separation of responsibilities  

---

## **3. Polymorphism (same interface, different behavior)**

Pipeline does:

```python
for step in self.steps:
    df = step.apply(df)
````

But `apply()` produces different effects:

* `HeaderNormalizer` renames columns
* `PIIRemover` drops sensitive columns
* `TypeCaster` enforces correct data types

This allows:

* Extensibility (plug in new Transformers easily)
* Reversible ordering
* Cleaner, simpler Pipeline logic

### Why is this important?

Researchers often want different cleaning orders:
e.g.,

* Normalize headers â†’ drop PII â†’ cast types
  vs.
* Drop PII â†’ normalize â†’ cast types

Polymorphism enables this flexibility without changing Pipeline code.

---

# ğŸ§© Design Pattern Usage

## **1. Template Method Pattern (Primary Pattern Used)**

`Transformer.apply()` acts as a **template**:

1. Run `_preflight()`
2. Call subclass `_apply()`
3. Log results
4. Return cleaned data

Subclasses override only `_apply()`, not the entire flow.

---

## **2. Strategy Pattern**

Each Transformer subclass represents a **strategy** for cleaning data.

Pipeline selects which strategy to apply at runtime.

This enables:

* Swappable behaviors
* Cleaner design
* Extensibility

---

## **3. Composition Pattern**

`Pipeline` coordinates independent strategy objects rather than inheriting them.

---

## **4. Separation of Concerns**

* Cleaning logic in Transformers
* Orchestration in Pipeline
* Validation in RulesValidator
* Reporting in ValidationReport

Clear modular responsibilities.

---

# ğŸ”„ Data Flow Example

```
1. User passes raw DataFrame to Pipeline.run(df)

2. Pipeline iterates over Transformers:
      step.apply(df)

3. Each transformer:
      - validates required columns
      - runs its subclass cleaning logic
      - logs result

4. Cleaned DataFrame returned

5. RulesValidator checks cleaned data:
      â†’ ValidationReport

6. ValidationReport summarizes structural or logical issues
```

---

# ğŸ’¾ I/O & Persistence Architecture

Our system includes a dedicated I/O layer (`io_utils.py`) responsible for file handling, serialization, and error safety. This layer is required for Project 4â€™s persistence feature set.

## File Loading
### `load_raw_csv(path)`
- Uses `pandas.read_csv` with exception handling  
- Ensures unreadable or missing files trigger descriptive errors  
- Returns a clean DataFrame for the pipeline

## Output Writing
### `save_cleaned_csv(df, output_path)`
- Writes the cleaned DataFrame to disk
- Automatically creates directories if they donâ€™t exist
- Ensures atomic writes to avoid partial corruption

### `save_validation_report(report, output_path)`
- Accepts either text or Markdown output
- Writes human-readable validation issues
- Ensures export consistency across runs

## State Persistence
### `save_state(state_dict, state_path)`
- Saves a JSON representation of:
  - config
  - pipeline history
  - timestamped runs
- Allows the application to be resumed or repeated deterministically

### `load_state(state_path)`
- Safely loads JSON state
- Handles:
  - missing files  
  - malformed JSON  
  - unexpected schema
- Supports the â€œoptional state modeâ€ in `app.py`

**Why separate I/O from business logic?**
- Prevents pipeline classes from doing file operations  
- Keeps the system modular and testable  
- Allows unit tests to mock or isolate file I/O  

# ğŸš€ Application Runner (`app.py`)

The `app.py` module is the high-level interface that ties together all major subsystems (Pipeline, Validators, and I/O).

## Responsibilities

### 1. Argument Parsing
The CLI supports:
- Input CSV path
- Output directory path
- Optional `--state-file`
- Optional `--no-state` mode

This provides an end-user interface suitable for real-world researchers.

### 2. Workflow Orchestration
`run_workflow(input_csv, output_dir, state_path=None)`:
1. Loads raw CSV  
2. Constructs Pipeline with default Transformers  
3. Runs the pipeline  
4. Validates cleaned data  
5. Saves cleaned CSV  
6. Saves validation report  
7. Saves state (unless suppressed)

### 3. Error Handling
- Missing input file â†’ non-zero exit code  
- Pipeline errors â†’ logged and surfaced cleanly  
- Invalid types / malformed CSV â†’ validation report still generated  

### 4. Integration Layer
`app.py` is the only module that:
- Talks to both I/O utilities and Transformers  
- Bundles multiple subsystems into a coherent user workflow  
- Ensures Project 4â€™s â€œcomplete end-to-end systemâ€ requirement is met

This separates â€œcore system logicâ€ from â€œexecution logic,â€ improving maintainability.

# ğŸ§  Design Decisions Summary

Below is a concise summary of key design decisions made in the architecture:

### 1. Use of Abstract Base Transformer
Provides a consistent interface and enforces preflight checks. Ensures subclasses focus only on their specific transformation logic.

### 2. Pipeline as a Composition Container
Pipeline uses (has-a) transformers instead of inheriting from them. This keeps responsibilities clean, allows reordering steps, and supports extensibility.

### 3. Template Method Pattern
`apply()` defines shared transformation flow. `_apply()` is overridden per transformer. Ensures consistent behavior while supporting customization.

### 4. Strategy Pattern for Transformers
Each transformer is a strategy for cleaning. This allows swapping, extending, and reordering cleaning behaviors without modifying pipeline code.

### 5. Separation of Concerns
Cleaning, validation, I/O, and orchestration reside in separate modules. Improves maintainability and testing.

### 6. Dedicated I/O Layer
File loading, saving, and state persistence are isolated in `io_utils.py` to avoid coupling business logic with file operations.

### 7. Application Runner Design
`app.py` coordinates the entire workflow and exposes a CLI interface. This follows best practices for real-world data processing tools.

### 8. JSON State Persistence
State is saved in JSON so runs are repeatable and to meet Project 4 persistence requirements.
